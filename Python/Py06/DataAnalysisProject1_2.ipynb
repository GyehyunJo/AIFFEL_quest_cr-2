{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF/0x+rXHafabYMUedLNLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSIMulti/AIFFEL_quest_cr/blob/master/Python/Py06/DataAnalysisProject1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요?\n",
        "  ● 정밀도(Precision) : 모델이 긍정으로 예측한 것 중 실제 긍정인 비율. 높을수록 좋음.\n",
        "  ● 재현율(Recall) : 실제 긍정 중 모델이 올바르게 예측한 비율. 높을수록 좋음.\n",
        "  ● F1 점수 : 정밀도와 재현율의 조화 평균. 두 지표의 균형을 평가\n",
        "  ● 지원(Support) : 각 클래스의 실제 샘플 수. 성능 평가 시 참고\n",
        "\n",
        "2. 모델의 성능을 평가하는 지표로는 무엇이 좋을까요?\n",
        "  ● F1 점수 : 정밀도와 재현율의 균형을 고려하므로 클래스 불균형이 있는 경우 유용\n",
        "  ● 정확도(Accuracy) : 전체 샘플 중 올바르게 예측한 비율. 클래스 불균형에 민감\n",
        "\n",
        "3. sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요.\n",
        "  ● F1 점수 추천\n",
        "  ● 이유 : 클래스 불균형이 있을 때 모델 성능을 더 잘 반영하기 때문"
      ],
      "metadata": {
        "id": "3X1iCBCEdA82"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG7IuqNZa8Yu",
        "outputId": "da347a3e-e7c0-42a2-fcdd-a80cdf32d99c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Names: ['class_0' 'class_1' 'class_2']\n",
            "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
            "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
            "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
            "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
            "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
            "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
            "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
            "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
            "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
            "\n",
            "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
            "count     178.000000  178.000000            178.000000       178.000000   \n",
            "mean        2.295112    2.029270              0.361854         1.590899   \n",
            "std         0.625851    0.998859              0.124453         0.572359   \n",
            "min         0.980000    0.340000              0.130000         0.410000   \n",
            "25%         1.742500    1.205000              0.270000         1.250000   \n",
            "50%         2.355000    2.135000              0.340000         1.555000   \n",
            "75%         2.800000    2.875000              0.437500         1.950000   \n",
            "max         3.880000    5.080000              0.660000         3.580000   \n",
            "\n",
            "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
            "count       178.000000  178.000000                    178.000000   178.000000  \n",
            "mean          5.058090    0.957449                      2.611685   746.893258  \n",
            "std           2.318286    0.228572                      0.709990   314.907474  \n",
            "min           1.280000    0.480000                      1.270000   278.000000  \n",
            "25%           3.220000    0.782500                      1.937500   500.500000  \n",
            "50%           4.690000    0.965000                      2.780000   673.500000  \n",
            "75%           6.200000    1.120000                      3.170000   985.000000  \n",
            "max          13.000000    1.710000                      4.000000  1680.000000  \n",
            "Decision Tree Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.93      0.93      0.93        14\n",
            "     class_1       0.93      1.00      0.97        14\n",
            "     class_2       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.95      0.93      0.94        36\n",
            "weighted avg       0.95      0.94      0.94        36\n",
            "\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      1.00      1.00        14\n",
            "     class_1       1.00      0.93      0.96        14\n",
            "     class_2       0.89      1.00      0.94         8\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.96      0.98      0.97        36\n",
            "weighted avg       0.98      0.97      0.97        36\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      1.00      1.00        14\n",
            "     class_1       0.73      0.79      0.76        14\n",
            "     class_2       0.57      0.50      0.53         8\n",
            "\n",
            "    accuracy                           0.81        36\n",
            "   macro avg       0.77      0.76      0.76        36\n",
            "weighted avg       0.80      0.81      0.80        36\n",
            "\n",
            "SGD Classifier Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.67      1.00      0.80        14\n",
            "     class_1       0.86      0.43      0.57        14\n",
            "     class_2       0.50      0.50      0.50         8\n",
            "\n",
            "    accuracy                           0.67        36\n",
            "   macro avg       0.67      0.64      0.62        36\n",
            "weighted avg       0.70      0.67      0.64        36\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      1.00      1.00        14\n",
            "     class_1       1.00      1.00      1.00        14\n",
            "     class_2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "wine_data = load_wine()  # 데이터 로드\n",
        "\n",
        "X = wine_data.data  # Feature Data\n",
        "y = wine_data.target  # Label Data\n",
        "\n",
        "target_names = wine_data.target_names\n",
        "print(\"Target Names:\", target_names)\n",
        "\n",
        "wine_df = pd.DataFrame(data=X, columns=wine_data.feature_names)  # DataFrame으로 변환하여 설명\n",
        "print(wine_df.describe())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dt_model = DecisionTreeClassifier()  # 결정 트리 모델 학습\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "\n",
        "rf_model = RandomForestClassifier()  # 랜덤 포레스트 모델 학습\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "\n",
        "svm_model = SVC()  # SVM 모델 학습\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "sgd_model = SGDClassifier()  # SGD 분류기 모델 학습\n",
        "sgd_model.fit(X_train, y_train)\n",
        "sgd_predictions = sgd_model.predict(X_test)\n",
        "\n",
        "scaler = StandardScaler()  # 로지스틱 회귀 모델 학습을 위한 스케일링\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "logistic_model = LogisticRegression(max_iter=500)\n",
        "logistic_model.fit(X_train_scaled, y_train)  # 스케일링된 데이터로 학습\n",
        "logistic_predictions = logistic_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, dt_predictions, target_names=target_names))  # 평가 지표 출력\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_predictions, target_names=target_names))\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_predictions, target_names=target_names))\n",
        "print(\"SGD Classifier Classification Report:\\n\", classification_report(y_test, sgd_predictions, target_names=target_names))\n",
        "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, logistic_predictions, target_names=target_names))"
      ]
    }
  ]
}