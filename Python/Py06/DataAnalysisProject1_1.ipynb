{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXTy6x4tEnGOVs8FiYBuQp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSIMulti/AIFFEL_quest_cr/blob/master/Python/Py06/DataAnalysisProject1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요?\n",
        "> 모델이 새로운 데이터에 대해 얼마나 잘 예측했는지를 보여줍니다.\n",
        "  정확도 : 맞춘 비율.\n",
        "  혼동 행렬 : 예측 결과를 세부적으로 분석.\n",
        "  클래스별 성능 : 정밀도, 재현율, F1-score로 각 클래스의 성능 평가.\n",
        "\n",
        "2. 모델의 성능을 평가하는 지표로는 무엇이 좋을까요?\n",
        "> 정확도 : 전체 맞춘 비율\n",
        "  정밀도 : 양성 예측 중 실제 양성 비율\n",
        "  재현율 : 실제 양성 중 양성 예측 비율\n",
        "  F1-score : 정밀도와 재현율의 조화 평균\n",
        "  ROC-AUC : 이진 분류 성능 평가\n",
        "\n",
        "3. sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요.\n",
        "> F1-score 선택\n",
        "> 정밀도와 재현율의 균형을 고려하여 데이터 불균형 상황에서 유용하게 사용할 수 있음"
      ],
      "metadata": {
        "id": "H5O8G8UoX-E3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aD5cAFoOW7N",
        "outputId": "5745ed85-a34a-482c-93d9-86f816f0094c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Data Shape: (1797, 64)\n",
            "Label Data Shape: (1797,)\n",
            "Target Names: [0 1 2 3 4 5 6 7 8 9]\n",
            "Decision Tree Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.88      0.92        33\n",
            "           1       0.96      0.79      0.86        28\n",
            "           2       0.79      0.79      0.79        33\n",
            "           3       0.74      0.85      0.79        34\n",
            "           4       0.81      0.93      0.87        46\n",
            "           5       0.93      0.91      0.92        47\n",
            "           6       0.89      0.94      0.92        35\n",
            "           7       0.91      0.88      0.90        34\n",
            "           8       0.80      0.67      0.73        30\n",
            "           9       0.85      0.88      0.86        40\n",
            "\n",
            "    accuracy                           0.86       360\n",
            "   macro avg       0.87      0.85      0.86       360\n",
            "weighted avg       0.87      0.86      0.86       360\n",
            "\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98        33\n",
            "           1       0.97      1.00      0.98        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       0.97      1.00      0.99        34\n",
            "           4       0.98      1.00      0.99        46\n",
            "           5       0.94      1.00      0.97        47\n",
            "           6       1.00      0.97      0.99        35\n",
            "           7       0.97      0.97      0.97        34\n",
            "           8       1.00      0.93      0.97        30\n",
            "           9       0.97      0.93      0.95        40\n",
            "\n",
            "    accuracy                           0.98       360\n",
            "   macro avg       0.98      0.98      0.98       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       1.00      1.00      1.00        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       1.00      1.00      1.00        46\n",
            "           5       0.98      0.98      0.98        47\n",
            "           6       0.97      1.00      0.99        35\n",
            "           7       0.97      0.97      0.97        34\n",
            "           8       1.00      0.97      0.98        30\n",
            "           9       0.95      0.95      0.95        40\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n",
            "SGD Classifier Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       0.90      1.00      0.95        28\n",
            "           2       0.97      1.00      0.99        33\n",
            "           3       1.00      0.97      0.99        34\n",
            "           4       1.00      0.98      0.99        46\n",
            "           5       0.94      0.94      0.94        47\n",
            "           6       0.97      0.97      0.97        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       0.93      0.90      0.92        30\n",
            "           9       0.95      0.95      0.95        40\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.97       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        33\n",
            "           1       0.97      1.00      0.98        28\n",
            "           2       0.97      1.00      0.99        33\n",
            "           3       0.97      0.97      0.97        34\n",
            "           4       1.00      0.98      0.99        46\n",
            "           5       0.92      0.94      0.93        47\n",
            "           6       0.97      0.97      0.97        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       0.97      0.97      0.97        30\n",
            "           9       0.97      0.95      0.96        40\n",
            "\n",
            "    accuracy                           0.97       360\n",
            "   macro avg       0.97      0.97      0.97       360\n",
            "weighted avg       0.97      0.97      0.97       360\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "\n",
        "digits = load_digits()\n",
        "\n",
        "X = digits.data  # Feature Data\n",
        "\n",
        "y = digits.target  # Label Data\n",
        "\n",
        "target_names = digits.target_names  # Target Names\n",
        "\n",
        "print(\"Feature Data Shape:\", X.shape)  # 데이터 Describe\n",
        "print(\"Label Data Shape:\", y.shape)\n",
        "print(\"Target Names:\", target_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "models = {  # 모델 초기화\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"SGD Classifier\": SGDClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
        "}\n",
        "\n",
        "target_names = [str(i) for i in digits.target_names]  # Target Names를 문자열로 변환\n",
        "\n",
        "for model_name, model in models.items():  # 모델 학습 및 예측\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"{model_name} Classification Report:\\n\", classification_report(y_test, y_pred, target_names=target_names))"
      ]
    }
  ]
}