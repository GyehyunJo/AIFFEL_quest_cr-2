{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiKB+0ievHrnLrZ5cmP+bf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSIMulti/AIFFEL_quest_cr/blob/master/Python/Py06/DataAnalysisProject1_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요?\n",
        "> 테스트 데이터 예측 결과 해석\n",
        "  ● 정확도(Accuracy) : 전체 예측 중 맞춘 비율\n",
        "  ● 정밀도(Precision) : 양성 예측 중 실제 양성 비율\n",
        "  ● 재현율(Recall) : 실제 양성 중 올바르게 예측한 비율\n",
        "  ● F1 점수 : 정밀도와 재현율의 조화 평균\n",
        "\n",
        "2. 모델의 성능을 평가하는 지표로는 무엇이 좋을까요?\n",
        "  ● F1 점수 : 클래스 불균형이 있을 때 정밀도와 재현율을 동시에 고려하여 모델 성능을 잘 반영\n",
        "\n",
        "3. sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요.\n",
        "  ● F1 점수 추천\n",
        "  ● 이유 : 유방암 데이터셋처럼 양성과 음성 클래스의 비율이 다를 수 있는 경우에 유용하기 때문"
      ],
      "metadata": {
        "id": "3sp_XhBmhshv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjhYCD_3hIbw",
        "outputId": "7da6f923-06f8-4115-f5eb-7923d661513c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Names: ['malignant' 'benign']\n",
            "       mean radius  mean texture  mean perimeter    mean area  \\\n",
            "count   569.000000    569.000000      569.000000   569.000000   \n",
            "mean     14.127292     19.289649       91.969033   654.889104   \n",
            "std       3.524049      4.301036       24.298981   351.914129   \n",
            "min       6.981000      9.710000       43.790000   143.500000   \n",
            "25%      11.700000     16.170000       75.170000   420.300000   \n",
            "50%      13.370000     18.840000       86.240000   551.100000   \n",
            "75%      15.780000     21.800000      104.100000   782.700000   \n",
            "max      28.110000     39.280000      188.500000  2501.000000   \n",
            "\n",
            "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
            "count       569.000000        569.000000      569.000000           569.000000   \n",
            "mean          0.096360          0.104341        0.088799             0.048919   \n",
            "std           0.014064          0.052813        0.079720             0.038803   \n",
            "min           0.052630          0.019380        0.000000             0.000000   \n",
            "25%           0.086370          0.064920        0.029560             0.020310   \n",
            "50%           0.095870          0.092630        0.061540             0.033500   \n",
            "75%           0.105300          0.130400        0.130700             0.074000   \n",
            "max           0.163400          0.345400        0.426800             0.201200   \n",
            "\n",
            "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
            "count     569.000000              569.000000  ...    569.000000   \n",
            "mean        0.181162                0.062798  ...     16.269190   \n",
            "std         0.027414                0.007060  ...      4.833242   \n",
            "min         0.106000                0.049960  ...      7.930000   \n",
            "25%         0.161900                0.057700  ...     13.010000   \n",
            "50%         0.179200                0.061540  ...     14.970000   \n",
            "75%         0.195700                0.066120  ...     18.790000   \n",
            "max         0.304000                0.097440  ...     36.040000   \n",
            "\n",
            "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
            "count     569.000000       569.000000   569.000000        569.000000   \n",
            "mean       25.677223       107.261213   880.583128          0.132369   \n",
            "std         6.146258        33.602542   569.356993          0.022832   \n",
            "min        12.020000        50.410000   185.200000          0.071170   \n",
            "25%        21.080000        84.110000   515.300000          0.116600   \n",
            "50%        25.410000        97.660000   686.500000          0.131300   \n",
            "75%        29.720000       125.400000  1084.000000          0.146000   \n",
            "max        49.540000       251.200000  4254.000000          0.222600   \n",
            "\n",
            "       worst compactness  worst concavity  worst concave points  \\\n",
            "count         569.000000       569.000000            569.000000   \n",
            "mean            0.254265         0.272188              0.114606   \n",
            "std             0.157336         0.208624              0.065732   \n",
            "min             0.027290         0.000000              0.000000   \n",
            "25%             0.147200         0.114500              0.064930   \n",
            "50%             0.211900         0.226700              0.099930   \n",
            "75%             0.339100         0.382900              0.161400   \n",
            "max             1.058000         1.252000              0.291000   \n",
            "\n",
            "       worst symmetry  worst fractal dimension  \n",
            "count      569.000000               569.000000  \n",
            "mean         0.290076                 0.083946  \n",
            "std          0.061867                 0.018061  \n",
            "min          0.156500                 0.055040  \n",
            "25%          0.250400                 0.071460  \n",
            "50%          0.282200                 0.080040  \n",
            "75%          0.317900                 0.092080  \n",
            "max          0.663800                 0.207500  \n",
            "\n",
            "[8 rows x 30 columns]\n",
            "Decision Tree Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.93      0.93      0.93        43\n",
            "      benign       0.96      0.96      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.94      0.94      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.98      0.93      0.95        43\n",
            "      benign       0.96      0.99      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   malignant       1.00      0.86      0.92        43\n",
            "      benign       0.92      1.00      0.96        71\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.96      0.93      0.94       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "SGD Classifier Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   malignant       1.00      0.88      0.94        43\n",
            "      benign       0.93      1.00      0.97        71\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.94      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.98      0.95      0.96        43\n",
            "      benign       0.97      0.99      0.98        71\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()  # 유방암 데이터 로드\n",
        "\n",
        "X = data.data  # Feature Data 지정하기\n",
        "y = data.target  # Label Data 지정하기\n",
        "\n",
        "target_names = data.target_names  # Target Names 출력해 보기\n",
        "print(\"Target Names:\", target_names)\n",
        "\n",
        "df = pd.DataFrame(X, columns=data.feature_names)  # 데이터 Describe 해 보기\n",
        "print(df.describe())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # train, test 데이터 분리\n",
        "\n",
        "scaler = StandardScaler()  # 데이터 스케일링\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "models = {  # 모델 초기화\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"SGD Classifier\": SGDClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000)  # max_iter 증가\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():  # 모델 학습 및 예측\n",
        "    if model_name == \"Logistic Regression\":\n",
        "        # 스케일링된 데이터를 사용하여 Logistic Regression 모델 학습\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        # 다른 모델은 원본 데이터를 사용하여 학습\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"{model_name} Classification Report:\\n\", classification_report(y_test, y_pred, target_names=target_names))"
      ]
    }
  ]
}